Here are exercises for the Buffer Manager visualization tool, "view_bufmgr."
This tool reads a trace file that lists the actions of the Buffer Manager
during a run of minibase, and shows you its internal state during the run.

Each exercise corresponds to a test case that is generated by the "bmtrace"
program.  You can vary the number of frames available to the Buffer Manager,
and the page replacement strategy (LRU, MRU, or Clock) used by the Buffer
Manager during each test case.  The general approach for each of these
exercises is: run "bmtrace" with the appropriate test number, capture its
output in a file, run "view_bufmgr" to see how the buffer manager behaved
during the run, then answer the questions.  You might have to generate several
traces for a given exercise.

You are free to examine the source code for bmtrace.C.  You are free to change
it to explore different alternatives.


1. Test case 1: Linear scan of single file.  Run "bmtrace 1" to generate a
   trace file for this case, then view it using "view_bufmgr."
  a. What does the Buffer Manager do for each page?
  b. What is the maximum pin count for each page?
  c. What happens when the number of frames in the buffer is smaller than the
     number of pages in the file: generate another trace with 16 frames in the
     buffer pool, and compare with your first trace.

2. Test case 2: Linear scan with occasional writes.  Run with 16 frames.
  a. What happens when a dirty frame is reused?
  b. How many writes are done, versus the number of dirties?

3. Test case 3: Several linear scans of single file.
  a. What happens when the number of frames available is greater than or equal
     to the number of pages in file? (Try setting the number of frames equal to
     36.)
  b. What happens when the number of frames available is less than the number
     of pages in file, for each replacement policy: LRU, MRU, Clock?  (Try each
     with the number of frames at 16.)
  c. How do the different replacement policies differ when the whole file fits
     in the buffer pool?

4. Test case 4: Several scans of one file with occasional reads from another
   file.  What is the critical point (i.e. #frames available) for flooding
   under each replacement policy?

5. Test case 5: Page nested loops scan.  What is the critical point
   (i.e. #frames available) for flooding under each replacement policy

6. Test case 6: Block nested loops join, strategy 1.  Here we simulate a block
   nested loops join with the outer file having 40 pages and the inner file
   having 15 pages.  The strategy is to pin as much of the first file at once
   as possible, then walk through the second file one page at a time.
  a. How many page I/Os happen when the whole first file fits in the buffer?
  b. How many page I/Os happen when the whole first file does not fit in the buffer?
  c. How does replacement policy affect this join strategy?

7. Test case 7: Block nested loops join, strategy 2.  This is a variant on test
   case 6 where we read both files in blocks.
  a. How many page I/Os happen when both files fit in the buffer (64 frames,
     e.g.)?
  b. How many page I/Os happen when the second file fits but the first file
     does not (36, e.g.)?
  c. How many page I/Os happen when neither whole file fits (25, e.g.)?
  d. "Blocked" I/O (i.e., simultaneous reading or writing of more than one page
     at a time) is often cheaper than normal, one-page-at-a-time, I/O.  Examine
     the two block nested loops strategies from this viewpoint.  Under what
     circumstances, and for what assumptions about the cost of blocked I/O,
     does strategy 2 beat strategy 1?

8. Test case 8: Clustered index scan.
  a. How many page I/Os to walk the file using the index if the whole file fits?
  b. How is it sensitive to number of frames in the buffer pool?

9. Test case 9: Unclustered index scan.
  a. How many page I/Os to walk the file using the index if the whole file fits?
  b. How is it sensitive to number of available frames?

10. Test case 10: Index nested loops join.  Here we simulate doing a file scan
    of a 20-page relation, and for each tuple using an index to access related
    tuples from a second 40-page relation.  You will need to examine the source
    code (function "indexNestedLoops" in file "bmtrace.C") to answer some of
    these questions.
  a. What is the critical factor for minimizing I/Os for this pattern?
  b. What is the effect of the different replacement policies on this pattern?
  c. Is the index (in the simulation) clustered or unclustered?
  d. What in the simulation would have to be changed to accurately simulate an
     index with the opposite clustering property?
  e. Assuming that the join being simulated is an equijoin, what would have to
     be changed to accurately simulate an index on a key of relation 2?
  f. If the join was an equijoin and the index was on a key of relation 2, what
     effect would a clustered vs. unclustered index have on the pattern of page
     access?

//11. external sort file  [Not there yet]
//  a. how many page I/Os happen when the whole file fits in the buffer
//  a. what happens when fewer frames are available than the size of the file
//  b. what happens when fewer frames are available than 1/2 the size of the file

